# 3rdSemester_Generative_Models

Домашнее задание №1 (vo_HW)
Это домашнее задание состоит из двух частей:

I часть.Реализовать безусловную генерацию картинок при помощи VAE тренированную на датасете MNIST и оценить качество по метрике FID.
II часть.Реализовать условную генерацию по классу.
Ссылка на коллаб: https://colab.research.google.com/drive/195rJ6x7619-2fyhVbSwbohxeOFvNTZNX

Структура и анализ кода

#### 1. Подготовка (Setup)
* !pip install pytorch-fid: Устанавливается специальная библиотека для подсчёта метрики FID, которая нужна, чтобы объективно оценить, насколько сгенерированные картинки похожи на настоящие.
* Импорт библиотек: Загружаются все необходимые инструменты: torch для нейросетей, torchvision для работы с картинками, matplotlib для визуализации и т.д.

#### 2. Подготовка данных (Data Preparation)
*train_loader: Загружается тренировочная часть датасета MNIST (картинки цифр 28x28 пикселей). Данные нормализуются, чтобы нейросети было легче их учить.
* real_dir и test_loader: Из тестовой части датасета сохраняется 10 000 настоящих изображений в отдельную папку. Они нужны будут как эталон для сравнения при расчёте FID.

Визуализация: Ты выводишь на экран по 5 случайных примеров из тренировочных и тестовых данных, чтобы убедиться, что данные загружены корректно и посмотреть, с чем предстоит работать.

#### 3. Часть I: Обычный (Безусловный) VAE
* **Класс VAE:** Здесь описана архитектура первой нейросети.
* **Энкодер (encode)** сжимает картинку в два параметра: среднее (mu) и логарифм дисперсии (logvar). Это и есть "вариационная" часть.
* **Трюк репараметризации (reparameterize)** — это стандартный для VAE приём, который позволяет обучать модель, несмотря на случайность.
* **Декодер (decode)** пытается восстановить исходную картинку из сжатого представления (z).
* **Функция потерь (vae_loss)**: Это формула, по которой модель понимает, насколько хорошо она учится. Она складывается из двух частей:
* recon_term (BCE): Проверяет, насколько восстановленная картинка похожа на оригинал.
* kl_term (KL-divergence): Следит за тем, чтобы сжатое представление (z) было организовано правильно и не "запутывалось".
* Тренировка: Модель обучается 20 эпох. После каждой эпохи выводится значение ошибки, и в конце рисуется график, как ошибка уменьшалась со временем. Это показывает, что обучение прошло успешно.

**Генерация и оценка (FID):**
* Генерируется 10 000 новых, "фейковых" изображений и сохраняется в папку fake_dir.
* С помощью функции fid_score.calculate_fid_given_paths сравниваются папки с реальными и сгенерированными картинками.
* **Результат:** Получается значение FID = 45.93. Это число — расстояние между "реальным" и "сгенерированным" мирами. Чем оно меньше, тем лучше.

#### 4. Часть II: Условный VAE (Conditional VAE)
* **Класс CVAE:** Архитектура очень похожа на обычный VAE, но с одним важным отличием: и энкодер, и декодер на вход получают не только картинку/латентный вектор, но и информацию о классе (c), то есть о том, какая цифра должна быть на картинке. Класс подаётся в виде one-hot вектора.

* **Тренировка CVAE:** Процесс обучения идентичен обычному VAE.
Генерация по классам:
* Для каждой цифры от 0 до 9 генерируется по 1000 изображений и сохраняется в отдельные папки.

**Оценка по классам:**
* Из тестовой выборки также формируются папки с реальными примерами для каждой цифры.
* Для каждого класса отдельно считается метрика FID, чтобы оценить, насколько хорошо модель научилась генерировать конкретные цифры.
* Выводятся результаты для каждого класса (например, Class 3: FID = 46.48).

#### 5. Выводы (Conclusions)

* Сравнение качества двух моделей.
* Отметили, для каких цифр CVAE справляется лучше, а для каких хуже.

Сделала вывод, что даже простые архитектуры неплохо работают на простых данных, но для сложных задач нужны сети посложнее.
